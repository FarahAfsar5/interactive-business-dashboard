{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvqRrZff4s38",
        "outputId": "a48a9de8-2982-4976-e09b-2f258ad30418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ streamlit_dashboard.py created inside the Colab session.\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "üåç Public URL (click to open): NgrokTunnel: \"https://d1750f9e24cd.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "‚ñ∂Ô∏è Streamlit started in the background. If the page doesn't load immediately, wait 10-20 seconds and refresh the Public URL above.\n"
          ]
        }
      ],
      "source": [
        "# ---------- FULL ONE-CELL SCRIPT FOR GOOGLE COLAB ----------\n",
        "# Run the whole cell in Colab. It will:\n",
        "# 1) install packages\n",
        "# 2) write streamlit_dashboard.py\n",
        "# 3) start ngrok and run Streamlit, printing a public URL to open.\n",
        "\n",
        "# 1) Install packages\n",
        "!pip install -q streamlit pandas plotly openpyxl numpy pyngrok\n",
        "\n",
        "# 2) Write the Streamlit app file (streamlit_dashboard.py)\n",
        "dashboard_code = r'''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from io import StringIO\n",
        "\n",
        "st.set_page_config(page_title=\"Interactive Business Dashboard\", layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
        "\n",
        "st.title(\"üìä Interactive Business Dashboard ‚Äî Global Superstore\")\n",
        "st.markdown(\"Upload your **Global Superstore dataset (CSV or Excel)** to explore Sales, Profit, and Segment-wise performance.\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_data(file) -> pd.DataFrame:\n",
        "    try:\n",
        "        if file.name.lower().endswith((\".xls\", \".xlsx\")):\n",
        "            df = pd.read_excel(file, engine=\"openpyxl\")\n",
        "        else:\n",
        "            content = file.read()\n",
        "            if isinstance(content, (bytes, bytearray)):\n",
        "                content = content.decode('utf-8', errors='replace')\n",
        "            df = pd.read_csv(StringIO(content))\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Failed to read file: {e}\")\n",
        "        return pd.DataFrame()\n",
        "    return df\n",
        "\n",
        "def clean_prepare(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df.empty:\n",
        "        return df\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip().replace(' ', '_') for c in df.columns]\n",
        "\n",
        "    # Convert date-like columns\n",
        "    for c in df.columns:\n",
        "        if \"date\" in c.lower():\n",
        "            df[c] = pd.to_datetime(df[c], errors='coerce')\n",
        "\n",
        "    # Numeric conversions\n",
        "    for col in ['Sales', 'Profit', 'Quantity', 'Discount']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Map common names to consistent names\n",
        "    rename_map = {}\n",
        "    col_map = {\n",
        "        'Sales': ['Sales', 'sales'],\n",
        "        'Profit': ['Profit', 'profit'],\n",
        "        'Region': ['Region', 'region'],\n",
        "        'Category': ['Category', 'category'],\n",
        "        'Sub-Category': ['Sub-Category', 'sub_category', 'Sub_Category'],\n",
        "        'Customer Name': ['Customer Name', 'Customer', 'customer_name', 'customer'],\n",
        "        'Order Date': ['Order Date', 'Order_Date', 'OrderDate', 'order_date']\n",
        "    }\n",
        "    for key, vals in col_map.items():\n",
        "        for v in vals:\n",
        "            if v in df.columns:\n",
        "                rename_map[v] = key\n",
        "    if rename_map:\n",
        "        df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "    # Fill missing categorical columns\n",
        "    for c in ['Region', 'Category', 'Sub-Category', 'Customer Name']:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].fillna(\"Unknown\").astype(str)\n",
        "\n",
        "    # Ensure Sales and Profit are numeric\n",
        "    for c in ['Sales', 'Profit']:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0.0)\n",
        "\n",
        "    # Year and Month\n",
        "    if 'Order Date' in df.columns:\n",
        "        df['Year'] = df['Order Date'].dt.year\n",
        "        df['Month'] = df['Order Date'].dt.month\n",
        "    else:\n",
        "        df['Year'] = np.nan\n",
        "        df['Month'] = np.nan\n",
        "\n",
        "    return df\n",
        "\n",
        "def compute_kpis(df):\n",
        "    total_sales = df['Sales'].sum() if 'Sales' in df.columns else 0.0\n",
        "    total_profit = df['Profit'].sum() if 'Profit' in df.columns else 0.0\n",
        "    return total_sales, total_profit\n",
        "\n",
        "# Sidebar: file upload and filters\n",
        "st.sidebar.header(\"üìÇ Upload & Filters\")\n",
        "uploaded_file = st.sidebar.file_uploader(\"Upload Global Superstore dataset (CSV / Excel)\", type=['csv','xlsx','xls'])\n",
        "\n",
        "if uploaded_file is None:\n",
        "    st.sidebar.info(\"No file uploaded yet. You can upload a CSV or Excel file exported from Global Superstore dataset.\")\n",
        "    st.stop()\n",
        "\n",
        "with st.spinner(\"Loading data...\"):\n",
        "    raw_df = load_data(uploaded_file)\n",
        "    if raw_df.empty:\n",
        "        st.error(\"Uploaded file couldn't be read or it is empty. Please try another file.\")\n",
        "        st.stop()\n",
        "    df = clean_prepare(raw_df)\n",
        "\n",
        "# Filter widgets\n",
        "regions = [\"All\"] + sorted(df['Region'].unique()) if 'Region' in df.columns else [\"All\"]\n",
        "categories = [\"All\"] + sorted(df['Category'].unique()) if 'Category' in df.columns else [\"All\"]\n",
        "subcats = [\"All\"] + sorted(df['Sub-Category'].unique()) if 'Sub-Category' in df.columns else [\"All\"]\n",
        "\n",
        "selected_regions = st.sidebar.multiselect(\"Region\", options=regions, default=[\"All\"])\n",
        "selected_categories = st.sidebar.multiselect(\"Category\", options=categories, default=[\"All\"])\n",
        "selected_subcats = st.sidebar.multiselect(\"Sub-Category\", options=subcats, default=[\"All\"])\n",
        "\n",
        "# Apply filters\n",
        "filtered = df.copy()\n",
        "if 'Region' in filtered.columns and selected_regions and \"All\" not in selected_regions:\n",
        "    filtered = filtered[filtered['Region'].isin(selected_regions)]\n",
        "if 'Category' in filtered.columns and selected_categories and \"All\" not in selected_categories:\n",
        "    filtered = filtered[filtered['Category'].isin(selected_categories)]\n",
        "if 'Sub-Category' in filtered.columns and selected_subcats and \"All\" not in selected_subcats:\n",
        "    filtered = filtered[filtered['Sub-Category'].isin(selected_subcats)]\n",
        "\n",
        "# KPIs row\n",
        "total_sales, total_profit = compute_kpis(filtered)\n",
        "col1, col2 = st.columns([2,2])\n",
        "col1.metric(\"üí∞ Total Sales\", f\"${total_sales:,.2f}\")\n",
        "col2.metric(\"üìà Total Profit\", f\"${total_profit:,.2f}\")\n",
        "\n",
        "# Top 5 customers by sales\n",
        "st.subheader(\"üèÜ Top 5 Customers by Sales\")\n",
        "if 'Customer Name' in filtered.columns and 'Sales' in filtered.columns:\n",
        "    top_customers = (filtered.groupby('Customer Name')['Sales']\n",
        "                     .sum()\n",
        "                     .sort_values(ascending=False)\n",
        "                     .head(5)\n",
        "                     .reset_index())\n",
        "    fig_top = px.bar(top_customers, x='Customer Name', y='Sales', title=\"Top 5 Customers by Sales\", text_auto='.2s')\n",
        "    st.plotly_chart(fig_top, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"Customer Name or Sales column not found in dataset.\")\n",
        "\n",
        "# Sales & Profit over time\n",
        "st.subheader(\"üìÖ Sales and Profit Over Time\")\n",
        "if 'Order Date' in filtered.columns:\n",
        "    ts = (filtered.groupby('Order Date')[['Sales','Profit']].sum().reset_index().sort_values('Order Date'))\n",
        "    if not ts.empty:\n",
        "        fig_ts = px.line(ts, x='Order Date', y=['Sales','Profit'], labels={'value':'Amount', 'variable':'Metric'}, title=\"Sales & Profit Over Time\")\n",
        "        st.plotly_chart(fig_ts, use_container_width=True)\n",
        "    else:\n",
        "        st.info(\"No time-series data after grouping by Order Date.\")\n",
        "else:\n",
        "    st.info(\"Order Date column not detected; cannot show time series.\")\n",
        "\n",
        "# Category & Sub-Category performance\n",
        "st.subheader(\"üì¶ Category & Sub-Category Performance\")\n",
        "if 'Category' in filtered.columns and 'Sales' in filtered.columns:\n",
        "    cat_perf = (filtered.groupby('Category')[['Sales','Profit']].sum().reset_index().sort_values('Sales', ascending=False))\n",
        "    fig_cat = px.bar(cat_perf, x='Category', y=['Sales','Profit'], barmode='group', title=\"Category Performance (Sales vs Profit)\")\n",
        "    st.plotly_chart(fig_cat, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"Category or Sales column missing.\")\n",
        "\n",
        "# Region performance\n",
        "st.subheader(\"üåç Region Performance\")\n",
        "if 'Region' in filtered.columns and 'Sales' in filtered.columns:\n",
        "    reg_perf = filtered.groupby('Region')[['Sales','Profit']].sum().reset_index().sort_values('Sales', ascending=False)\n",
        "    fig_reg = px.bar(reg_perf, x='Region', y='Sales', title=\"Sales by Region\")\n",
        "    st.plotly_chart(fig_reg, use_container_width=True)\n",
        "else:\n",
        "    st.info(\"Region or Sales column missing.\")\n",
        "\n",
        "# Data table with ability to download filtered dataset\n",
        "st.subheader(\"üìã Filtered Data Preview\")\n",
        "st.dataframe(filtered.head(200))\n",
        "\n",
        "def convert_df_to_csv_bytes(df):\n",
        "    return df.to_csv(index=False).encode('utf-8')\n",
        "\n",
        "csv_bytes = convert_df_to_csv_bytes(filtered)\n",
        "st.download_button(\"‚¨áÔ∏è Download Filtered Data as CSV\", data=csv_bytes, file_name=\"filtered_global_superstore.csv\", mime=\"text/csv\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"**Notes & Tips:**\")\n",
        "st.markdown(\"- If your dataset uses different column names, the app attempts to detect common variants (e.g., 'Customer', 'Customer Name', 'Sales', 'Profit').\")\n",
        "st.markdown(\"- For large datasets (>200k rows) the app may be slower; consider sampling or filtering by Year/Region first.\")\n",
        "st.markdown(\"- Want additional visuals (maps, cohort analysis, custom KPIs)? Ask me and I will extend the app.\")\n",
        "'''\n",
        "with open(\"streamlit_dashboard.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(dashboard_code)\n",
        "print(\"‚úÖ streamlit_dashboard.py created inside the Colab session.\")\n",
        "\n",
        "!ngrok config add-authtoken 31gleRJuq8LsVqX7iLmKVdlT6R2_5ZnS8nFLiJaTyDQ3dfJ5\n",
        "\n",
        "# 3) Start ngrok tunnel and run Streamlit\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Kill any old tunnels\n",
        "try:\n",
        "    ngrok.kill()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Start a new tunnel on port 8501\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåç Public URL (click to open):\", public_url)\n",
        "\n",
        "# Start Streamlit in the background\n",
        "get_ipython().system_raw('streamlit run streamlit_dashboard.py --server.port 8501 --server.headless true &')\n",
        "\n",
        "# Wait a little for the app to boot\n",
        "time.sleep(5)\n",
        "print(\"‚ñ∂Ô∏è Streamlit started in the background. If the page doesn't load immediately, wait 10-20 seconds and refresh the Public URL above.\")\n",
        "# ------------------------------------------------------------\n"
      ]
    }
  ]
}